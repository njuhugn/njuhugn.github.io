<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="stylesheet/jemdoc.css" type="text/css" />
<link rel="stylesheet" href="stylesheet/styles.css" type="text/css" />
<title>Guangneng HU</title>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<link rel="stylesheet" href="fontawesome-free-6.0.0-beta2-web/css/fontawesome.min.css">
</head>
<div class="infoblock">
<div class="blockcontent">
<p><b>&nbsp; &nbsp;<a href="https://njuhugn.github.io/index.html">[Back to Homepage]</a></b>
</span></p>
</div></div>

<body>
<div class="infoblock">
<div class="blocktitle">News: World</div>
<div class="blockcontent">
<p><a href="https://blog.neurips.cc/2021/11/30/announcing-the-neurips-2021-award-recipients/" target="blank">[30 Nov 21] NeurIPS 2021 Awards:</a></p>
<strong>Outstanding Papers</strong> (Award committee: Alice Oh, Daniel Hsu, Emma Brunskill, Kilian Weinberger, and Yisong Yue)
  <ul>
  <li><a>A Universal Law of Robustness via Isoperimetry</a> 
  <br>Sébastien Bubeck and Mark Sellke. </li>

  <li><a>On the Expressivity of Markov Reward</a> 
  <br>David Abel, Will Dabney, Anna Harutyunyan, Mark K. Ho, Michael Littman, Doina Precup, and Satinder Singh. </li>

  <li><a>Deep Reinforcement Learning at the Edge of the Statistical Precipice</a> 
  <br>Rishabh Agarwal, Max Schwarzer, Pablo Samuel Castro, Aaron Courville, and Marc G. Bellemare. </p>

  <li><a>MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers</a> 
  <br>Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun, Sean Welleck, Yejin Choi, and Zaid Harchaoui. </li>

  <li><a>Continuized Accelerations of Deterministic and Stochastic Gradient Descents, and of Gossip Algorithms</a> 
  <br>Mathieu Even, Raphaël Berthier, Francis Bach, Nicolas Flammarion, Pierre Gaillard, Hadrien Hendrikx, Laurent Massoulié, and Adrien Taylor. </li>

  <li><a>Moser Flow: Divergence-based Generative Modeling on Manifolds</a> 
  <br>Noam Rozen, Aditya Grover, Maximilian Nickel, and Yaron Lipman.</li>
  </ul>
<strong>Test of Time Award</strong> (Award committee: Joelle Pineau, Léon Bottou, Max Welling, and Ulrike von Luxburg)
  <ul>
  <li><a>Online Learning for Latent Dirichlet Allocation</a> (NIPS 2010)
  <br>Matthew Hoffman, David Blei, and Francis Bach.</li>
  </ul>
</div>

</body>
</html>