<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="stylesheet/jemdoc.css" type="text/css" />
<link rel="stylesheet" href="stylesheet/styles.css" type="text/css" />
<title>Guangneng HU</title>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  "tex2jax": {
    "inlineMath": [["$","$"], ["\\(","\\)"]],
    "displayMath": [["\\[","\\]"]],
    "processEscapes": true
  }
});
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<link rel="stylesheet" href="fontawesome-free-6.0.0-beta2-web/css/fontawesome.min.css">
</head>
<div class="infoblock">
<div class="blockcontent">
<p><b>&nbsp; &nbsp;<a href="https://njuhugn.github.io/index.html">[Back to Homepage]</a></b>
</span></p>
</div></div>

<style>
table {
  border-collapse: collapse;
  width: 100%;
}
th, td {
  text-align: left;
  padding: 8px;
}
tr:nth-child(even) {background-color: #f2f2f2;}
</style>
<!--
<table>
<tbody>
  <tr>
    <td class="left"><strong>序号</strong></td>
    <td class="left"><strong>项目编号</strong></td>
    <td class="left"><strong>项目名称</strong></td>
    <td class="left"><strong>项目牵头单位</strong></td>
    <td class="left"><strong>项目实施周期（年）</strong></td>
  </tr>
</tbody>
</table>
-->

<body>
<div class="infoblock">
<div class="blocktitle">News: World</div>
<div class="blockcontent">
<p><a>[Dec 14 2021]</a> NeurIPS'21 <font color="crimson">Oral</font> Papers</p>
<table>
<tbody>
<tr>
  <td class="left">1</td>
  <td class="left"><a>Framing RNN as a kernel method: A neural ODE approach</a></td>
  <td class="left">Adeline Fermanian · Pierre Marion · Jean-Philippe Vert · Gérard Biau</td>
</tr>
<tr>
  <td class="left">2</td>
  <td class="left"><a>$E(n)$ Equivariant Normalizing Flows</a></td>
  <td class="left">Victor Garcia Satorras · Emiel Hoogeboom · Fabian Fuchs · Ingmar Posner · Max Welling</td>
</tr>
<tr>
  <td class="left">3</td>
  <td class="left"><a>MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers</a></td>
  <td class="left">Krishna Pillutla · Swabha Swayamdipta · Rowan Zellers · John Thickstun · Sean Welleck · Yejin Choi · Zaid Harchaoui</td>
</tr>
<tr>
  <td class="left">4</td>
  <td class="left"><a>Separation Results between Fixed-Kernel and Feature-Learning Probability Metrics</a></td>
  <td class="left">Carles Domingo i Enrich · Youssef Mroueh</td>
</tr>
<tr>
  <td class="left">5</td>
  <td class="left"><a>Learning to Draw: Emergent Communication through Sketching</a></td>
  <td class="left">Daniela Mihai · Jonathon Hare</td>
</tr>
<tr>
  <td class="left">6</td>
  <td class="left"><a>A Universal Law of Robustness via Isoperimetry</a></td>
  <td class="left">Sebastien Bubeck · Mark Sellke</td>
</tr>
<tr>
  <td class="left">7</td>
  <td class="left"><a>Near-Optimal No-Regret Learning in General Games</a></td>
  <td class="left">Constantinos Daskalakis · Maxwell Fishelson · Noah Golowich</td>
</tr>
<tr>
  <td class="left">8</td>
  <td class="left"><a>Online Variational Filtering and Parameter Learning</a></td>
  <td class="left">Andrew Campbell · Yuyang Shi · Tom Rainforth · Arnaud Doucet</td>
</tr>
<tr>
  <td class="left">9</td>
  <td class="left"><a>Alias-Free Generative Adversarial Networks</a></td>
  <td class="left">Tero Karras · Miika Aittala · Samuli Laine · Erik Härkönen · Janne Hellsten · Jaakko Lehtinen · Timo Aila</td>
</tr>
<tr>
  <td class="left">10</td>
  <td class="left"><a>Lower Bounds on Metropolized Sampling Methods for Well-Conditioned Distributions</a></td>
  <td class="left">Yin Tat Lee · Ruoqi Shen · Kevin Tian</td>
</tr>
<tr>
  <td class="left">11</td>
  <td class="left"><a>Causal Identification with Matrix Equations</a></td>
  <td class="left">Sanghack Lee · Elias Bareinboim</td>
</tr>
<tr>
  <td class="left">12</td>
  <td class="left"><a>Latent Equilibrium: A unified learning theory for arbitrarily fast computation with arbitrarily slow neurons</a></td>
  <td class="left">Paul Haider · Benjamin Ellenberger · Laura Kriener · Jakob Jordan · Walter Senn · Mihai A. Petrovici</td>
</tr>
<tr>
  <td class="left">13</td>
  <td class="left"><a>EF21: A New, Simpler, Theoretically Better, and Practically Faster Error Feedback</a></td>
  <td class="left">Peter Richtarik · Igor None Sokolov · Ilyas Fatkhullin</td>
</tr>
<tr>
  <td class="left">14</td>
  <td class="left"><a>Attention over Learned Object Embeddings Enables Complex Visual Reasoning</a></td>
  <td class="left">David Ding · Felix Hill · Adam Santoro · Malcolm Reynolds · Matt Botvinick</td>
</tr>
<tr>
  <td class="left">15</td>
  <td class="left"><a>Data driven semi-supervised learning</a></td>
  <td class="left">Maria-Florina Balcan · Dravyansh Sharma</td>
</tr>
<tr>
  <td class="left">16</td>
  <td class="left"><a>An Exponential Lower Bound for Linearly Realizable MDP with Constant Suboptimality Gap</a></td>
  <td class="left">Yuanhao Wang · Ruosong Wang · Sham Kakade</td>
</tr>
<tr>
  <td class="left">17</td>
  <td class="left"><a>Differentiable Quality Diversity</a></td>
  <td class="left">Matthew Fontaine · Stefanos Nikolaidis</td>
</tr>
<tr>
  <td class="left">18</td>
  <td class="left"><a>Stability and Deviation Optimal Risk Bounds with Convergence Rate $O(1/n)$</a></td>
  <td class="left">Yegor Klochkov · Nikita Zhivotovskiy</td>
</tr>
<tr>
  <td class="left">19</td>
  <td class="left"><a>Learning Frequency Domain Approximation for Binary Neural Networks</a></td>
  <td class="left">Yixing Xu · Kai Han · Chang Xu · Yehui Tang · Chunjing XU · Yunhe Wang</td>
</tr>
<tr>
  <td class="left">20</td>
  <td class="left"><a>On the Expressivity of Markov Reward</a></td>
  <td class="left">Dave Abel · Will Dabney · Anna Harutyunyan · Mark Ho · Michael Littman · Doina Precup · Satinder Singh</td>
</tr>
<tr>
  <td class="left">21</td>
  <td class="left"><a>Learning Debiased Representation via Disentangled Feature Augmentation</a></td>
  <td class="left">Jungsoo Lee · Eungyeup Kim · Juyoung Lee · Jihyeon Lee · Jaegul Choo</td>
</tr>
<tr>
  <td class="left">22</td>
  <td class="left"><a>Hessian Eigenspectra of More Realistic Nonlinear Models</a></td>
  <td class="left">Zhenyu Liao · Michael W Mahoney</td>
</tr>
<tr>
  <td class="left">23</td>
  <td class="left"><a>The Complexity of Bayesian Network Learning: Revisiting the Superstructure</a></td>
  <td class="left">Robert Ganian · Viktoriia Korchemna</td>
</tr>
<tr>
  <td class="left">24</td>
  <td class="left"><a>The best of both worlds: stochastic and adversarial episodic MDPs with unknown transition</a></td>
  <td class="left">Tiancheng Jin · Longbo Huang · Haipeng Luo</td>
</tr>
<tr>
  <td class="left">25</td>
  <td class="left"><a>Continuized Accelerations of Deterministic and Stochastic Gradient Descents, and of Gossip Algorithms</a></td>
  <td class="left">Mathieu Even · Raphaël Berthier · Francis Bach · Nicolas Flammarion · Hadrien Hendrikx · Pierre Gaillard · Laurent Massoulié · Adrien Taylor</td>
</tr>
<tr>
  <td class="left">26</td>
  <td class="left"><a>Unsupervised Speech Recognition</a></td>
  <td class="left">Alexei Baevski · Wei-Ning Hsu · Alexis CONNEAU · Michael Auli</td>
</tr>
<tr>
  <td class="left">27</td>
  <td class="left"><a>Efficient First-Order Contextual Bandits: Prediction, Allocation, and Triangular Discrimination</a></td>
  <td class="left">Dylan J Foster · Akshay Krishnamurthy</td>
</tr>
<tr>
  <td class="left">28</td>
  <td class="left"><a>Partial success in closing the gap between human and machine vision</a></td>
  <td class="left">Robert Geirhos · Kantharaju Narayanappa · Benjamin Mitzkus · Tizian Thieringer · Matthias Bethge · Felix A. Wichmann · Wieland Brendel</td>
</tr>
<tr>
  <td class="left">29</td>
  <td class="left"><a>Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers</a></td>
  <td class="left">Mandela Patrick · Dylan Campbell · Yuki Asano · Ishan Misra · Florian Metze · Christoph Feichtenhofer · Andrea Vedaldi · João Henriques</td>
</tr>
<tr>
  <td class="left">30</td>
  <td class="left"><a>Deep Reinforcement Learning at the Edge of the Statistical Precipice</a></td>
  <td class="left">Rishabh Agarwal · Max Schwarzer · Pablo Samuel Castro · Aaron Courville · Marc Bellemare</td>
</tr>
<tr>
  <td class="left">31</td>
  <td class="left"><a>Oracle Complexity in Nonsmooth Nonconvex Optimization</a></td>
  <td class="left">Guy Kornowski · Ohad Shamir</td>
</tr>
<tr>
  <td class="left">32</td>
  <td class="left"><a>Bellman-consistent Pessimism for Offline Reinforcement Learning</a></td>
  <td class="left">Tengyang Xie · Ching-An Cheng · Nan Jiang · Paul Mineiro · Alekh Agarwal</td>
</tr>
<tr>
  <td class="left">33</td>
  <td class="left"><a>Faster Matchings via Learned Duals</a></td>
  <td class="left">Michael Dinitz · Sungjin Im · Thomas Lavastida · Benjamin Moseley · Sergei Vassilvitskii</td>
</tr>
<tr>
  <td class="left">34</td>
  <td class="left"><a>A Compositional Atlas of Tractable Circuit Operations for Probabilistic Inference</a></td>
  <td class="left">Antonio Vergari · YooJung Choi · Anji Liu · Stefano Teso · Guy Van den Broeck</td>
</tr>
<tr>
  <td class="left">35</td>
  <td class="left"><a>Volume Rendering of Neural Implicit Surfaces</a></td>
  <td class="left">Lior Yariv · Jiatao Gu · Yoni Kasten · Yaron Lipman</td>
</tr>
<tr>
  <td class="left">36</td>
  <td class="left"><a>Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss</a></td>
  <td class="left">Jeff Z. HaoChen · Colin Wei · Adrien Gaidon · Tengyu Ma</td>
</tr>
<tr>
  <td class="left">37</td>
  <td class="left"><a>Risk Monotonicity in Statistical Learning</a></td>
  <td class="left">Zakaria Mhammedi</td>
</tr>
<tr>
  <td class="left">38</td>
  <td class="left"><a>Passive attention in artificial neural networks predicts human visual selectivity</a></td>
  <td class="left">Thomas Langlois · Charles Zhao · Erin Grant · Ishita Dasgupta · Tom Griffiths · Nori Jacoby</td>
</tr>
<tr>
  <td class="left">39</td>
  <td class="left"><a>Shape As Points: A Differentiable Poisson Solver</a></td>
  <td class="left">Songyou Peng · Max Jiang · Yiyi Liao · Michael Niemeyer · Marc Pollefeys · Andreas Geiger</td>
</tr>
<tr>
  <td class="left">40</td>
  <td class="left"><a>Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds and Benign Overfitting</a></td>
  <td class="left">Frederic Koehler · Lijia Zhou · Danica Sutherland · Nathan Srebro</td>
</tr>
<tr>
  <td class="left">41</td>
  <td class="left"><a>The decomposition of the higher-order homology embedding constructed from the $k$-Laplacian</a></td>
  <td class="left">Yu-Chia Chen · Marina Meila</td>
</tr>
<tr>
  <td class="left">42</td>
  <td class="left"><a>Optimal Rates for Random Order Online Optimization</a></td>
  <td class="left">Uri Sherman · Tomer Koren · Yishay Mansour</td>
</tr>
<tr>
  <td class="left">43</td>
  <td class="left"><a>Moser Flow: Divergence-based Generative Modeling on Manifolds</a></td>
  <td class="left">Noam Rozen · Aditya Grover · Maximilian Nickel · Yaron Lipman</td>
</tr>
<tr>
  <td class="left">44</td>
  <td class="left"><a>MERLOT: Multimodal Neural Script Knowledge Models</a></td>
  <td class="left">Rowan Zellers · Ximing Lu · Jack Hessel · Yj Yu · Jae Sung Park · Jize Cao · Ali Farhadi · Yejin Choi</td>
</tr>
<tr>
  <td class="left">45</td>
  <td class="left"><a>Interesting Object, Curious Agent: Learning Task-Agnostic Exploration</a></td>
  <td class="left">Simone Parisi · Victoria Dean · Deepak Pathak · Abhinav Gupta</td>
</tr>
<tr>
  <td class="left">46</td>
  <td class="left"><a>Evaluating Gradient Inversion Attacks and Defenses in Federated Learning</a></td>
  <td class="left">Yangsibo Huang · Samyak Gupta · Zhao Song · Kai Li · Sanjeev Arora</td>
</tr>
<tr>
  <td class="left">47</td>
  <td class="left"><a>DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras</a></td>
  <td class="left">Zachary Teed · Jia Deng</td>
</tr>
<tr>
  <td class="left">48</td>
  <td class="left"><a>Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification</a></td>
  <td class="left">Ben Eysenbach · Sergey Levine · Russ Salakhutdinov</td>
</tr>
<tr>
  <td class="left">49</td>
  <td class="left"><a>Retiring Adult: New Datasets for Fair Machine Learning</a></td>
  <td class="left">Frances Ding · Moritz Hardt · John Miller · Ludwig Schmidt</td>
</tr>
<tr>
  <td class="left">50</td>
  <td class="left"><a>Drop, Swap, and Generate: A Self-Supervised Approach for Generating Neural Activity</a></td>
  <td class="left">Ran Liu · Mehdi Azabou · Max Dabagia · Chi-Heng Lin · Mohammad Gheshlaghi Azar · Keith Hengen · Michal Valko · Eva Dyer</td>
</tr>
<tr>
  <td class="left">51</td>
  <td class="left"><a>High-probability Bounds for Non-Convex Stochastic Optimization with Heavy Tails</a></td>
  <td class="left">Ashok Cutkosky · Harsh Mehta</td>
</tr>
<tr>
  <td class="left">52</td>
  <td class="left"><a>Learning with Noisy Correspondence for Cross-modal Matching</a></td>
  <td class="left">Zhenyu Huang · Guocheng Niu · Xiao Liu · Wenbiao Ding · Xinyan Xiao · Hua Wu · Xi Peng</td>
</tr>
<tr>
  <td class="left">53</td>
  <td class="left"><a>Learning Treatment Effects in Panels with General Intervention Patterns</a></td>
  <td class="left">Vivek Farias · Andrew Li · Tianyi Peng</td>
</tr>
<tr>
  <td class="left">54</td>
  <td class="left"><a>Sequential Causal Imitation Learning with Unobserved Confounders</a></td>
  <td class="left">Daniel Kumor · Junzhe Zhang · Elias Bareinboim</td>
</tr>
<tr>
  <td class="left">55</td>
  <td class="left"><a>Adaptive Conformal Inference Under Distribution Shift</a></td>
  <td class="left">Isaac Gibbs · Emmanuel Candes</td>
</tr>
</tbody>
</table>


<p><a href="archive/国家重点研发计划“网络空间安全治理”重点专项2021年度拟立项项目公示清单.pdf" target="blank">[03 Dec 21] 国家重点研发计划“网络空间安全治理”重点专项2021年度拟立项项目公示清单</a></p>

<p><a href="https://blog.neurips.cc/2021/11/30/announcing-the-neurips-2021-award-recipients/" target="blank">[30 Nov 21] NeurIPS 2021 Awards:</a></p>
<strong>Outstanding Papers</strong> (Award committee: Alice Oh, Daniel Hsu, Emma Brunskill, Kilian Weinberger, and Yisong Yue)
  <ul>
  <li><a>A Universal Law of Robustness via Isoperimetry</a> 
  <br>Sébastien Bubeck and Mark Sellke. </li>

  <li><a>On the Expressivity of Markov Reward</a> 
  <br>David Abel, Will Dabney, Anna Harutyunyan, Mark K. Ho, Michael Littman, Doina Precup, and Satinder Singh. </li>

  <li><a>Deep Reinforcement Learning at the Edge of the Statistical Precipice</a> 
  <br>Rishabh Agarwal, Max Schwarzer, Pablo Samuel Castro, Aaron Courville, and Marc G. Bellemare. </p>

  <li><a>MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers</a> 
  <br>Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun, Sean Welleck, Yejin Choi, and Zaid Harchaoui. </li>

  <li><a>Continuized Accelerations of Deterministic and Stochastic Gradient Descents, and of Gossip Algorithms</a> 
  <br>Mathieu Even, Raphaël Berthier, Francis Bach, Nicolas Flammarion, Pierre Gaillard, Hadrien Hendrikx, Laurent Massoulié, and Adrien Taylor. </li>

  <li><a>Moser Flow: Divergence-based Generative Modeling on Manifolds</a> 
  <br>Noam Rozen, Aditya Grover, Maximilian Nickel, and Yaron Lipman.</li>
  </ul>
<strong>Test of Time Award</strong> (Award committee: Joelle Pineau, Léon Bottou, Max Welling, and Ulrike von Luxburg)
  <ul>
  <li><a>Online Learning for Latent Dirichlet Allocation</a> (NIPS 2010)
  <br>Matthew Hoffman, David Blei, and Francis Bach.</li>
  </ul>
</div>

</body>
</html>