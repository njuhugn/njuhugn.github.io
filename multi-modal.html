<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="stylesheet/jemdoc.css" type="text/css" />
<link rel="stylesheet" href="stylesheet/styles.css" type="text/css" />
<style>
table, th, td {
  border: 1px solid black;
  border-collapse: collapse;
}
th, td {
  padding: 5px;
}
th {
  text-align: left;
}
</style>

<title>Guangneng HU</title>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<link rel="stylesheet" href="fontawesome-free-6.0.0-beta2-web/css/fontawesome.min.css">
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">

<td id="layout-content">
<div id="toptitle">
<div class="call-out-green"><div style="font-size:36px; padding:13px 0px; font-family:Arial, Helvetica, sans-serif; font-weight:bold;";>Multimodal Learning Tasks [<i><a href="index.html">BackToHome</a></i>]</div></div>
</div>

<h2 style="CLEAR: both;">Multimodal NER</h2>
<ol reversed>  
<li><a href="paper/Multimodal Named Entity Recognition with Knowledge-Refined Cross-Modal Attention-wang-icme22.pdf" target="_blank">Multimodal Named Entity Recognition with Knowledge-Refined Cross-Modal Attention</a>. Wang et al., <i>ICME</i>, 2022

<li><a href="paper/A General Matching and Alignment Framework for Multimodal Named Entity Recognition-Xu-wsdm22.pdf" target="_blank">A General Matching and Alignment Framework for Multimodal Named Entity Recognition</a>. Xu et al. <i>WSDM</i>, 2022

<li><a href="paper/Pretraining Multi-modal Representations for Chinese NER Task with Cross-Modality Attention-Mai-wsdm22.pdf" target="_blank">Pretraining Multi-modal Representations for Chinese NER Task with Cross-Modality Attention</a>. Mai et al. <i>WSDM</i>, 2022


<li><a href="paper/Multi-modal Graph Fusion for Named Entity Recognition with Targeted Visual Guidance-Zhang-aaai21.pdf" target="_blank">Multi-modal Graph Fusion for Named Entity Recognition with Targeted Visual Guidance</a>. Zhang et al. <i>AAAI</i>, 2021

<li><a href="paper/Object-Aware Multimodal Named Entity Recognition in Social Media Posts With Adversarial Learning-Zhang-TMM21.pdf" target="_blank">Object-Aware Multimodal Named Entity Recognition in Social Media Posts With Adversarial Learning</a>. Zhang et al. <i>TMM</i>, 2021

<li><a href="paper/A Survey on Deep Learning for Named Entity Recognition-Li-tkde20.pdf" target="_blank">A Survey on Deep Learning for Named Entity Recognition</a>. Li et al. <i>TKDE</i>, 2020

<li><a href="paper/Improving Multimodal Named Entity Recognition via Entity Span Detection with Unified Multimodal Transformer-Yu-acl20.pdf" target="_blank">Improving Multimodal Named Entity Recognition via Entity Span Detection with Unified Multimodal Transformer</a>. Yu et al. <i>ACL</i>, 2020

<li><a href="paper/Multimodal Named Entity Recognition for Short Social Media Posts-Moon-naacl18.pdf" target="_blank">Multimodal Named Entity Recognition for Short Social Media Posts</a>. Moon et al. <i>NAACL</i>, 2018

<li><a href="paper/Adaptive Co-attention Network for Named Entity Recognition in Tweets-Zhang-aaai18.pdf" target="_blank">Adaptive Co-attention Network for Named Entity Recognition in Tweets</a>. Zhang et al. <i>AAAI</i>, 2018

<li><a href="paper/Visual Attention Model for Name Tagging in Multimodal Social Media-Lu-acl18.pdf" target="_blank">Visual Attention Model for Name Tagging in Multimodal Social Media</a>. Lu et al. <i>ACL</i>, 2018
</ol> 

<strong>Neural NER</strong> 
<ol reversed>  
<li><a href="paper/End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF-Ma-acl16.pdf" target="_blank">End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF</a>. Ma & Hovy. <i>ACL</i>, 2016
</ol> 

<h2 style="CLEAR: both;">Multimodal MT</h2>
<ol reversed>  
<li><a href="paper/A Shared Task on Multimodal Machine Translation and Crosslingual Image Description-Specia-WMT16.pdf" target="_blank">A Shared Task on Multimodal Machine Translation and Crosslingual Image Description</a>. Specia et al. <i>WMT</i>, 2016
</ol> 

<h2 style="CLEAR: both;">Multimodal IE</h2>
<ol reversed>  
<li><a href="paper/Modeling Dense Cross-Modal Interactions for Joint Entity-Relation Extraction-Zhao-ijcai20.pdf" target="_blank">Modeling Dense Cross-Modal Interactions for Joint Entity-Relation Extraction</a>. Zhao et al. <i>IJCAI</i>, 2020
</ol> 

<h2 style="CLEAR: both;">Multimodal Sentiment/ Emotion</h2>

<p> [<i><a href="index.html">BackToHome</a></i>]

</td>
</tr>
</table>
</body>
</html>